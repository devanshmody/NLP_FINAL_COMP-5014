{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1130532_textsummarynlpproject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qELybmgHs2e1",
        "outputId": "0a8aac24-d09c-4b29-c13a-132c0d63a5bf"
      },
      "source": [
        "#step1 import all the required libraries\n",
        "#install this version of transformers and pytorch\n",
        "!pip install transformers==2.8.0\n",
        "!pip install torch==1.4.0\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import tensorflow_datasets as tfds\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import nltk,spacy,re,string,random,time\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input,LSTM,Embedding,Dense,Concatenate,TimeDistributed,Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "from attension import AttentionLayer\n",
        "from keras.initializers import Constant\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K \n",
        "from rouge import rouge_n,rouge_l_sentence_level,rouge \n",
        "from bleau import compute_bleu\n",
        "#disable eager execution\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "#stopwords removal list\n",
        "nltk.download('stopwords')\n",
        "#punkt for tokenization\n",
        "nltk.download('punkt')\n",
        "#for tokenaizations\n",
        "nltk.download('wordnet')\n",
        "#combine all the stopwords and create one single list of stopwords\n",
        "s1=stopwords.words('english')\n",
        "s2=list(STOP_WORDS)\n",
        "s3=list(STOPWORDS)\n",
        "#final list of stopwords\n",
        "stop_words = s1+s2+s3\n",
        "#use cuda if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#step2\n",
        "#contraction are used to replace words with their longer meaningfull counter parts \n",
        "contraction = { \n",
        "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
        "\"aren't\": \"are not / am not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had / he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he shall / he will\",\n",
        "\"he'll've\": \"he shall have / he will have\",\n",
        "\"he's\": \"he has / he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how has / how is / how does\",\n",
        "\"I'd\": \"I had / I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I shall / I will\",\n",
        "\"I'll've\": \"I shall have / I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had / it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it shall / it will\",\n",
        "\"it'll've\": \"it shall have / it will have\",\n",
        "\"it's\": \"it has / it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had / she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she shall / she will\",\n",
        "\"she'll've\": \"she shall have / she will have\",\n",
        "\"she's\": \"she has / she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as / so is\",\n",
        "\"that'd\": \"that would / that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that has / that is\",\n",
        "\"there'd\": \"there had / there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there has / there is\",\n",
        "\"they'd\": \"they had / they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they shall / they will\",\n",
        "\"they'll've\": \"they shall have / they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had / we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall / what will\",\n",
        "\"what'll've\": \"what shall have / what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what has / what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when has / when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where has / where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who shall / who will\",\n",
        "\"who'll've\": \"who shall have / who will have\",\n",
        "\"who's\": \"who has / who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why has / why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had / you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you shall / you will\",\n",
        "\"you'll've\": \"you shall have / you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\",\n",
        "\"rec'd\": \"received\"\n",
        "}\n",
        "#rec'd this is my addition to the list of contractions\n",
        "\n",
        "#step3\n",
        "#process_text function is used to remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings\n",
        "def process_text(text,contractions,remove_stopwords = True):\n",
        "  #convert words to lower case\n",
        "  text = text.lower()\n",
        "    \n",
        "  #replace contractions with their longer forms \n",
        "  if True:\n",
        "    text = text.split()\n",
        "    new_text = []\n",
        "    for word in text:\n",
        "      if word in contractions:\n",
        "        new_text.append(contractions[word])\n",
        "      else:\n",
        "        new_text.append(word)\n",
        "    text = \" \".join(new_text)\n",
        "    \n",
        "  #format words and remove unwanted characters\n",
        "  text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) #remove https string\n",
        "  text = re.sub(r'\\<a href', ' ', text) #remove hyperlink\n",
        "  text = re.sub(r'&amp;', '', text) #remove & in text\n",
        "  text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text) #remove unwanted charecters like puntuation and others\n",
        "  text = re.sub(r'<br />', ' ', text) #remove new line spaces\n",
        "  text = re.sub(r'\\'', ' ', text) #remove slashes\n",
        "  text = \" \".join(text.split()) #remove trailing spaces \n",
        "  #string.printable returns all sets of punctuation, digits, ascii_letters and whitespace.\n",
        "  printable = set(string.printable)\n",
        "  #filter to remove punctuations,digits, ascii_letters and whitespaces\n",
        "  text = \"\".join(list(filter(lambda x: x in printable, text))) \n",
        "  #remove stop words is true then remove stopwords also\n",
        "  if remove_stopwords:\n",
        "    text = text.split()\n",
        "    text = [w for w in text if not w in stop_words]\n",
        "    text = \" \".join(text)\n",
        "\n",
        "  return text\n",
        "\n",
        "#step4\n",
        "#get_data function gets the data from gz file into a dataframe and process the columns\n",
        "#stops are not removed for summary they are only removed from text this is done to get more human like summaries\n",
        "#after processing it returns a dataframe\n",
        "def get_data(contractions):\n",
        "  st=time.time()\n",
        "  #load the data into a dataframe\n",
        "  df = pd.read_json('/content/drive/MyDrive/reviews_Clothing_Shoes_and_Jewelry_5.json.gz', lines=True, compression='gzip')\n",
        "  #drop unwanted columns\n",
        "  df.drop(columns=['reviewerID', 'asin', 'reviewerName', 'helpful','overall','unixReviewTime', 'reviewTime'],inplace=True)\n",
        "  print(\"length of the data\",len(df))\n",
        "  #apply preprocess function on the columns of the dataframe\n",
        "  df['reviewText'] = df['reviewText'].apply(lambda x: process_text(x,contractions,remove_stopwords = True))\n",
        "  df['summary'] = df[ 'summary'].apply(lambda x: process_text(x,contractions,remove_stopwords = False))\n",
        "  #write preprocesssed data to csv file\n",
        "  df.to_csv(\"/content/drive/MyDrive/product_reviews.csv\",index=False)\n",
        "  print(\"total time to generate data and write in csv file \",time.time()-st)\n",
        "\n",
        "\n",
        "#step5\n",
        "#get_embeddings function is used to gett te word embeddings \n",
        "#i am using conceptual number batch word embeddings\n",
        "def get_embeddings():\n",
        "  #get word embeddings\n",
        "  embeddings_index = {}\n",
        "  with open('/content/drive/MyDrive/numberbatch-en-19.08.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "      values = line.split(' ')\n",
        "      word = values[0]\n",
        "      embedding = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = embedding\n",
        "\n",
        "  print('Word embeddings:', len(embeddings_index))\n",
        "  return embeddings_index\n",
        "\n",
        "#step6\n",
        "#this function is used to build vocabulary\n",
        "def get_vocab(embeddings_index,word_counts,threshold):\n",
        "  #get the number of missing words \n",
        "  missing_words={k:v for k,v in word_counts.items() if v >= threshold if k not in embeddings_index.keys()}\n",
        "  missing_ratio = round(len(missing_words)/len(word_counts),4)*100\n",
        "  print(\"Number of words missing from word_embeddings:\", len(missing_words))\n",
        "  print(\"Percent of words that are missing from our vocabulary: {}%\".format(missing_ratio))\n",
        "\n",
        "  #mapping vocab to index\n",
        "  lr=iter([item for item in range(0,len(word_counts))])\n",
        "  vocab_to_int={k:next(lr) for k,v in word_counts.items() if v >= threshold or k in embeddings_index.keys()}\n",
        "\n",
        "  #mapping index to vocab \n",
        "  lr=iter([item for item in range(0,len(word_counts))])\n",
        "  int_to_vocab={next(lr):k for k,v in word_counts.items() if v >= threshold or k in embeddings_index.keys()}\n",
        "\n",
        "  # Special tokens that will be added to our vocab\n",
        "  codes = [\"<UNK>\",\"<PAD>\",\"<EOS>\",\"<GO>\"]\n",
        "\n",
        "  # Add codes to vocab\n",
        "  for code in codes:\n",
        "      vocab_to_int[code] = len(vocab_to_int)\n",
        "      int_to_vocab[len(int_to_vocab)] = code\n",
        "  \n",
        "  #print usage of words in our model and their percent\n",
        "  usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n",
        "  print(\"Total number of unique words:\", len(word_counts))\n",
        "  print(\"Number of words we will use:\", len(vocab_to_int))\n",
        "  print(\"Percent of words we will use: {}%\".format(usage_ratio))\n",
        "  print(\"length vocab_to_int\",len(vocab_to_int))\n",
        "  print(\"length int_to_vocab\",len(int_to_vocab))\n",
        "\n",
        "  return vocab_to_int,int_to_vocab\n",
        "\n",
        "#step7\n",
        "#function to map words with its word embeddings \n",
        "#if embeddings not found for the word then map it with a random number in range(-1.0,1.0)\n",
        "def word_embedding_index(vocab_to_int,embeddings_index):\n",
        "  #using 300 for embedding dimensions to match CN's vectors.\n",
        "  embedding_dim = 300\n",
        "  nb_words = len(vocab_to_int)\n",
        "  \n",
        "  # Create matrix with default values of zero\n",
        "  word_embedding_matrix = np.zeros((nb_words, embedding_dim), dtype=np.float32)\n",
        "  for word, i in vocab_to_int.items():\n",
        "    if word in embeddings_index:\n",
        "      word_embedding_matrix[i] = embeddings_index[word]\n",
        "    else:\n",
        "      # If word not in CN, create a random embedding for it\n",
        "      new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
        "      #embeddings_index[word] = new_embedding\n",
        "      word_embedding_matrix[i] = new_embedding\n",
        "\n",
        "  # Check if value matches len(vocab_to_int)\n",
        "  print(\"length of word embedding matrix\",len(word_embedding_matrix))\n",
        "  return word_embedding_matrix\n",
        "\n",
        "#step8\n",
        "#append unk and eos tokens \n",
        "#if eos is equal to true then append go and eos token at begining and end of the summary\n",
        "#add unknown token for word not found in vocabulary\n",
        "def convert_to_ints(text,vocab_to_int,eos=False):\n",
        "  ints = []\n",
        "  for word in text.split():\n",
        "    if word in vocab_to_int:\n",
        "      ints.append(vocab_to_int[word])\n",
        "    else:\n",
        "      ints.append(vocab_to_int[\"<UNK>\"])\n",
        "  if eos:\n",
        "    ints.insert(0,vocab_to_int[\"<GO>\"])\n",
        "    ints.insert(len(ints),vocab_to_int[\"<EOS>\"])\n",
        "  return ints\n",
        "\n",
        "#step9\n",
        "#count unknown tokens\n",
        "def count_unk(text):\n",
        "  unk=0\n",
        "  eos=0\n",
        "  #print(text)\n",
        "  for value in text:\n",
        "    if 41413 in value:\n",
        "      unk+=1\n",
        "  return unk\n",
        "\n",
        "#step10\n",
        "def counts(val):\n",
        "  c=0\n",
        "  for i in val:\n",
        "    try:\n",
        "      if i==41413:\n",
        "        c+=1\n",
        "    except:\n",
        "      pass\n",
        "  return c\n",
        "\n",
        "#step11\n",
        "#remove rows from data frame that dosent staisfy the condition this is done so model is trained with proper data\n",
        "#redundancey is less and input text is accurate\n",
        "def get_refined_output(df,max_rl,max_sl):\n",
        "  unk_rl=1 #unknown token review limit\n",
        "  unk_sl=0 #unknown token summary limit\n",
        "  min_rl=2 #minimum review length\n",
        "  #get the total length of reviewText this is used for sorting\n",
        "  df[\"total_length\"]=df['reviewText'].apply(lambda x: len(x))\n",
        "  #get reviewText whose length is greater then minimum review length \n",
        "  df=df[df['reviewText'].apply(lambda x: len(x)>=min_rl)]\n",
        "  #get reviewText whose length is less than maximum review length\n",
        "  df=df[df['reviewText'].apply(lambda x: len(x)<=max_rl)]\n",
        "  #filter out the unknwon tokens based on unknown token reviewText limit\n",
        "  df=df[df['reviewText'].apply(lambda x: counts(x)<=unk_rl)]\n",
        "  #get summary whose length is less than maximum summary length\n",
        "  df=df[df['summary'].apply(lambda x: len(x)<=max_sl)]\n",
        "  #filter out the unkown tokens based on unkown token summary limit\n",
        "  df=df[df['summary'].apply(lambda x: counts(x)<=unk_sl)]  \n",
        "  #sort the values in ascending order\n",
        "  df.sort_values(by=[\"total_length\"],ascending=True,inplace=True)\n",
        "  #drop unwanted columns\n",
        "  df.drop(columns=[\"total_length\",\"word\"],inplace=True)\n",
        "  #reset index\n",
        "  df.reset_index(drop=True,inplace=True)\n",
        "  return df \n",
        "\n",
        "#step12\n",
        "#function to plot the length of training, validation and testing\n",
        "def plot_tr_tval_tt_len(xtr,xval,xtt):\n",
        "  names = ['Training','Validation','Testing']\n",
        "  values = [len(xtr),len(xval),len(xtt)]\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.subplot(131)\n",
        "  plt.bar(names,values,color=['darkorange','coral','coral'],edgecolor='darkblue')\n",
        "  plt.suptitle('Categorical Plotting')\n",
        "  plt.show()\n",
        "\n",
        "#step13\n",
        "#function to plot loss and accuracy curves on training and validation set\n",
        "def plotgraph(history):\n",
        "  plt.figure(figsize=[8,6])\n",
        "  plt.plot(history.history['loss'],'firebrick',linewidth=3.0)\n",
        "  plt.plot(history.history['accuracy'],'turquoise',linewidth=3.0)\n",
        "  plt.plot(history.history['val_loss'],'midnightblue',linewidth=3.0)\n",
        "  plt.legend(['Training loss','Training Accuracy','Validation loss'],fontsize=18)\n",
        "  plt.xlabel('Epochs',fontsize=16)\n",
        "  plt.ylabel('Loss and Accuracy',fontsize=16)\n",
        "  plt.title('Loss Curves and Accuracy Curves for text summarization',fontsize=16)\n",
        "\n",
        "#step14\n",
        "#this function is used to get the preprocessed csv file for our text summarizer\n",
        "def Get_the_data():\n",
        "  #lower the string in contractions and convert it into dict\n",
        "  contractions = dict((k.lower(), v.lower()) for k, v in contraction.items())\n",
        "  #till this step all data is processed and we get our csv file of cleaned texts\n",
        "  get_data(contractions)\n",
        "\n",
        "  #free memory\n",
        "  del contractions\n",
        "\n",
        "#step15 is used to call function Get_the_data which get the preprocessed data and writes it into a csv file\n",
        "#Get_the_data()\n",
        "\n",
        "#step16\n",
        "#this function combines all the above ouput generated by the above function in a proper squence of steps \n",
        "def combining_all_steps():\n",
        "  \n",
        "  st=time.time()\n",
        "  #get the final cleaned data\n",
        "  df=pd.read_csv('/content/drive/MyDrive/product_reviews.csv')[:180000]\n",
        "  print(\"The length of dataset is \",len(df))\n",
        "  #combine reviewText and summary so common vocabulary can be created by finding frequent words \n",
        "  df[\"word\"]=df[['reviewText','summary']].apply(lambda x : '{} {}'.format(x[0],x[1]), axis=1)\n",
        "  #get frequency of words\n",
        "  word_counts=pd.Series(np.concatenate([x.split() for x in df.word])).value_counts()\n",
        "  word_counts=word_counts.to_dict()\n",
        "  #print(type(word_counts))\n",
        "  print(\"vocab length\",len(word_counts))\n",
        "  #set the threshold \n",
        "  threshold = 20\n",
        "  max_rl=80 #maximum review length\n",
        "  max_sl=10 #maximum summary length\n",
        "  #get the embeddings matrix \n",
        "  embeddings_index= get_embeddings()\n",
        "  #get vocab to index and index to vocab mapping of words\n",
        "  vocab_to_int,int_to_vocab=get_vocab(embeddings_index,word_counts,threshold)\n",
        "  #get word embedding for the words in vocab\n",
        "  word_embedding_matrix=word_embedding_index(vocab_to_int,embeddings_index)\n",
        "  #convert words to integers based on their index positions\n",
        "  df['reviewText'] = df['reviewText'].apply(lambda x: convert_to_ints(str(x),vocab_to_int,eos=False))\n",
        "  df['summary'] = df[ 'summary'].apply(lambda x: convert_to_ints(str(x),vocab_to_int,eos=True))\n",
        "  print(\"after word to index for reviewText\",df[\"reviewText\"][0])\n",
        "  print(\"after word to index for summary\",df[\"summary\"][0])\n",
        "  rvunk=count_unk(df[\"reviewText\"])\n",
        "  smunk=count_unk(df[\"summary\"])\n",
        "  print(\"total number of unk token are\",rvunk+smunk)\n",
        "  #apply the filters and get the final preprocessed data\n",
        "  df=get_refined_output(df,max_rl,max_sl)\n",
        "  print(\"length of dataset that will be used\",len(df))\n",
        "  #split data into 75% train, 15% validation and 15% test datasets\n",
        "  x_tr,x_val,y_tr,y_val=train_test_split(df['reviewText'],df['summary'],test_size=0.3,random_state=1,shuffle=True)\n",
        "  x_tt,x_val,y_tt,y_val=train_test_split(x_val,y_val,test_size=0.5,random_state=1,shuffle=True)\n",
        "  print(\"length of split datasets train {}, test {} and validation {}\".format(len(x_tr),len(x_tt),len(x_val)))\n",
        "  print(\"Vocabulary Size: {}\".format(len(vocab_to_int)))\n",
        "  print(\"voc_to_int_\",vocab_to_int['<UNK>'],vocab_to_int['<PAD>'],vocab_to_int['<EOS>'])\n",
        "  #reset index\n",
        "  x_tr=x_tr.reset_index()\n",
        "  y_tr=y_tr.reset_index()\n",
        "  x_tt=x_tt.reset_index()\n",
        "  y_tt=y_tt.reset_index()\n",
        "  x_val=x_val.reset_index()\n",
        "  y_val=y_val.reset_index()\n",
        "  #find max lenght just to verfiy the output of get refined function\n",
        "  #max([len(sentence) for sentence in y_tt[\"summary\"]])\n",
        "  #pad the reviewText and summary to the specified max length\n",
        "  xtr=pad_sequences(x_tr[\"reviewText\"], padding='post',maxlen=max_rl, value=vocab_to_int[\"<PAD>\"])\n",
        "  ytr=pad_sequences(y_tr[\"summary\"], padding='post',maxlen=max_sl, value=vocab_to_int[\"<PAD>\"])\n",
        "  xtt=pad_sequences(x_tt[\"reviewText\"], padding='post',maxlen=max_rl, value=vocab_to_int[\"<PAD>\"])\n",
        "  ytt=pad_sequences(y_tt[\"summary\"], padding='post',maxlen=max_sl, value=vocab_to_int[\"<PAD>\"])\n",
        "  xval=pad_sequences(x_val[\"reviewText\"], padding='post',maxlen=max_rl, value=vocab_to_int[\"<PAD>\"])\n",
        "  yval=pad_sequences(y_val[\"summary\"], padding='post',maxlen=max_sl, value=vocab_to_int[\"<PAD>\"])\n",
        "  #find the number of unique tokens in the list\n",
        "  #flat_list_rt = [item for sublist in df[\"reviewText\"] for item in sublist]\n",
        "  #flat_list_s = [item for sublist in df[\"summary\"] for item in sublist]\n",
        "  #rt=len(np.unique(flat_list_rt))\n",
        "  #st=len(np.unique(flat_list_s))\n",
        "  #print(\"number of unique tokens reviewText {} and summary {}\".format(rt,st))\n",
        "  #plot the length of training, validation and testing\n",
        "  plot_tr_tval_tt_len(xtr,xval,xtt)\n",
        "  print(\"total time to complete all the above steps and get final data \",time.time()-st)\n",
        "  #free memory delete values stored in variables which are not required further\n",
        "  del df,word_counts,embeddings_index,x_tr,x_val,y_tr,y_val,x_tt,y_tt\n",
        "\n",
        "  return xtr,ytr,xtt,ytt,xval,yval,vocab_to_int,int_to_vocab,word_embedding_matrix,max_rl,max_sl  \n",
        "\n",
        "#step17\n",
        "#function to get summary given a sequence\n",
        "def seq_to_summary(seq,vocab_to_int,int_to_vocab):\n",
        "  newstring=''\n",
        "  for i in seq:\n",
        "    if ((i!=0 and i!=vocab_to_int['<GO>']) and i!=vocab_to_int['<EOS>']):\n",
        "      newstring=newstring+int_to_vocab[i]+' '\n",
        "  return newstring\n",
        "  \n",
        "#step18\n",
        "#function to get text given a sequence\n",
        "def seq_to_text(seq,int_to_vocab):\n",
        "  newstring=''\n",
        "  for i in seq:\n",
        "    if (i!=0):\n",
        "      newstring=newstring+int_to_vocab[i]+' '\n",
        "  return newstring\n",
        "\n",
        "#step19\n",
        "#this function get the data for the pretrained model t5small\n",
        "def combining_all_steps_t5():\n",
        "  #get the final cleaned data\n",
        "  df=pd.read_csv('/content/drive/MyDrive/product_reviews.csv')[:117799]\n",
        "  print(\"The length of dataset is \",len(df))\n",
        "  \n",
        "  #set the threshold \n",
        "  threshold = 20\n",
        "  max_rl=80 #maximum review length\n",
        "  max_sl=10 #maximum summary length\n",
        "  \n",
        "  #get reviewText whose length is less than maximum review length\n",
        "  df['reviewText']=df['reviewText'].str.slice(0,max_rl)\n",
        "  \n",
        "  #get summary whose length is less than maximum summary length\n",
        "  df['summary']=df['summary'].str.slice(0,max_rl)\n",
        "\n",
        "  #split data into 75% train, 15% validation and 15% test datasets\n",
        "  x_tr,x_val,y_tr,y_val=train_test_split(df['reviewText'],df['summary'],test_size=0.3,random_state=1,shuffle=True)\n",
        "  x_tt,x_val,y_tt,y_val=train_test_split(x_val,y_val,test_size=0.5,random_state=1,shuffle=True)\n",
        "\n",
        "  #reset index\n",
        "  x_tr=x_tr.reset_index()\n",
        "  y_tr=y_tr.reset_index()\n",
        "  x_tt=x_tt.reset_index()\n",
        "  y_tt=y_tt.reset_index()\n",
        "  x_val=x_val.reset_index()\n",
        "  y_val=y_val.reset_index()\n",
        "  print(\"train {}, val {}, test {}\".format(len(x_tr),len(x_val),len(x_tt)))\n",
        "  return x_tr,y_tr,x_tt,y_tt,x_val,y_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 8.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 17.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/e3/5e49e9a83fb605aaa34a1c1173e607302fecae529428c28696fb18f1c2c9/tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 22.5MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/60/78919d8b178668aac44b5d5f4fbe660880179ada1e9000cf3ee3bfcb6421/boto3-1.17.50.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.0.1)\n",
            "Collecting botocore<1.21.0,>=1.20.50\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/ae/e7e003597f954283f90f21891bda64bab0fc1738951aeb09a7c798ef0a60/botocore-1.20.50-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 51.7MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.50->boto3->transformers==2.8.0) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses, boto3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=7aef10d55e53e280f0d5bd52432a8ae532b82a709215041944d39a15bab58040\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "  Building wheel for boto3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for boto3: filename=boto3-1.17.50-py2.py3-none-any.whl size=128779 sha256=b2db93c465b66514c5b6766f91f706e5606f19b153f56dca7542adc6eb391467\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/e5/43/ef6fc36c3008477a35f9324c0e490c7aa20f7b51993a388267\n",
            "Successfully built sacremoses boto3\n",
            "\u001b[31mERROR: botocore 1.20.50 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, jmespath, botocore, s3transfer, boto3, transformers\n",
            "Successfully installed boto3-1.17.50 botocore-1.20.50 jmespath-0.10.0 s3transfer-0.3.6 sacremoses-0.0.44 sentencepiece-0.1.95 tokenizers-0.5.2 transformers-2.8.0\n",
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 22kB/s \n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "Successfully installed torch-1.4.0\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8TyGtX0STcy"
      },
      "source": [
        "#step20\n",
        "#function to design and evaluate the model\n",
        "def design_model_fit_eval(xtr,ytr,xval,yval,vocab_to_int,word_embedding_matrix,max_rl):\n",
        "  K.clear_session() \n",
        "  latent_dim = 80\n",
        "  embedding_dim=300\n",
        "  \n",
        "  # Encoder\n",
        "  encoder_inputs = Input(shape=(max_rl,))\n",
        "\n",
        "  #embedding layer\n",
        "  enc_emb =  Embedding(len(vocab_to_int),\n",
        "                        embedding_dim,\n",
        "                        embeddings_initializer=Constant(word_embedding_matrix),\n",
        "                        trainable=False)(encoder_inputs)\n",
        "\n",
        "  \n",
        "  #LSTM 1 \n",
        "  encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "  encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "  #LSTM 2 \n",
        "  encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "  encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "  #LSTM 3 \n",
        "  encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "  encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "  # Set up the decoder, using `encoder_states` as initial state.\n",
        "  decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "  #embedding layer\n",
        "  dec_emb_layer = Embedding(len(vocab_to_int),\n",
        "                            embedding_dim,\n",
        "                            embeddings_initializer=Constant(word_embedding_matrix),\n",
        "                            trainable=False)\n",
        "\n",
        "  #decoder\n",
        "  dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "  decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "  # Attention layer\n",
        "  attn_layer = AttentionLayer(name='attention_layer')\n",
        "  attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "  # Concat attention input and decoder LSTM output\n",
        "  decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "  #dense layer\n",
        "  decoder_dense =  TimeDistributed(Dense(len(vocab_to_int), activation='softmax'))\n",
        "  decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "  # Define the model \n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "  \n",
        "  #print model summary\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(optimizer='rmsprop',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  #reduce_lr method is used to reduce the learning rate if the learning rate is stagnant or if there are no major improvements in training\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                                patience=5, min_lr=0.001)\n",
        "  #early stopping condition\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "  \n",
        "  st=time.time()\n",
        "  \n",
        "  #fit te model\n",
        "  history=model.fit([xtr,ytr[:,:-1]], ytr.reshape(ytr.shape[0],ytr.shape[1], 1)[:,1:] ,epochs=100,callbacks=[es],batch_size=512, validation_data=([xval,yval[:,:-1]], yval.reshape(yval.shape[0],yval.shape[1], 1)[:,1:]))\n",
        "                  \n",
        "  #plot loss and accuracy curves\n",
        "  plotgraph(history)\n",
        "  print(\"total time required for training \",time.time()-st)\n",
        "  return encoder_inputs,encoder_outputs, state_h, state_c,decoder_inputs,decoder_lstm,attn_layer,decoder_dense,dec_emb_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYn29_aFd2oG"
      },
      "source": [
        "#step21\n",
        "#design of inference function\n",
        "def design_inference(encoder_inputs,encoder_outputs, state_h, state_c,decoder_inputs,decoder_lstm,attn_layer,decoder_dense,max_rl,dec_emb_layer):\n",
        "  #latent dimension\n",
        "  latent_dim = 80\n",
        "  \n",
        "  #encode the input sequence to get the feature vector\n",
        "  encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "  #decoder setup\n",
        "  #below tensors will hold the states of the previous time step\n",
        "  decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "  decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "  decoder_hidden_state_input = Input(shape=(max_rl,latent_dim))\n",
        "\n",
        "  #get the embeddings of the decoder sequence\n",
        "  dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "  #to predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "  #attention inference\n",
        "  attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "  decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "  #a dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "  #final decoder model\n",
        "  decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "                        [decoder_outputs2] + [state_h2, state_c2])\n",
        "  \n",
        "  return encoder_model,decoder_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtygGatZlCWO"
      },
      "source": [
        "#step22\n",
        "#fucntion to get the decoded squence for the given review \n",
        "def decode_sequence(input_seq,encoder_model,decoder_model,vocab_to_int,int_to_vocab,max_sl):\n",
        "  # Encode the input as state vectors.\n",
        "  e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "  # Generate empty target sequence of length 1.\n",
        "  target_seq = np.zeros((1,1))\n",
        "    \n",
        "  # Populate the first word of target sequence with the start word.\n",
        "  target_seq[0, 0] = vocab_to_int['<GO>']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "    # Sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_token = int_to_vocab[sampled_token_index]\n",
        "        \n",
        "    if (sampled_token!=\"<EOS>\"):\n",
        "      decoded_sentence += ' '+sampled_token\n",
        "      \n",
        "      # Exit condition: either hit max length or find stop word.\n",
        "      if (sampled_token == '<EOS>'  or len(decoded_sentence.split()) >= (max_sl-1)):\n",
        "        stop_condition = True\n",
        "\n",
        "    # Update the target sequence (of length 1).\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # Update internal states\n",
        "    e_h, e_c = h, c\n",
        "\n",
        "  return decoded_sentence\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEiX6WRESQcn"
      },
      "source": [
        "#step23\n",
        "#this function is used to get the score for LSTM scratch model designed and puts output in a txt file\n",
        "def test_scratch(xtt,ytt,int_to_vocab,vocab_to_int,encoder_model,decoder_model,max_sl,max_rl):\n",
        "  st=time.time()\n",
        "  predictions = []\n",
        "  real_og=[]\n",
        "  pred_op=[]\n",
        "  c=0\n",
        "  b=50\n",
        "  for i in range(0,len(xtt)):\n",
        "    #review\n",
        "    review=seq_to_text(xtt[i],int_to_vocab)\n",
        "    review=review.replace(\"<PAD>\",'')\n",
        "    #original summary   \n",
        "    og_summary=seq_to_summary(ytt[i],vocab_to_int,int_to_vocab)\n",
        "    og_summary=og_summary.replace(\"<PAD>\",'')\n",
        "    real_og.append(str(og_summary))\n",
        "    #predicted summary   \n",
        "    predict_summary=decode_sequence(xtt[i].reshape(1,max_rl),encoder_model,decoder_model,vocab_to_int,int_to_vocab,max_sl)\n",
        "    predict_summary=predict_summary.replace(\"<PAD>\",'')\n",
        "    pred_op.append(str(predict_summary))\n",
        "    #write to a text file name review_og_pred.txt\n",
        "    predictions.append(\"review:\"+review+\"\\t\"+\"orignal:\"+og_summary+\"\\t\"+\"predicted:\"+predict_summary+\"\\n\")\n",
        "    if c>b:\n",
        "      print(\"Review: {}\".format(review))\n",
        "      print(\"Original Summary: {}\".format(og_summary))\n",
        "      print(\"Predicted Summary: {}\".format(predict_summary))\n",
        "      b+=b\n",
        "    c+=1\n",
        "\n",
        "  print(\"total time to complete {}\".format(time.time()-st))\n",
        "  file = open(\"/content/drive/MyDrive/LSTMscore.txt\",\"w\")\n",
        "  file.writelines(predictions)\n",
        "  file.close()\n",
        "\n",
        "  bleau=compute_bleu(real_og,pred_op, max_order=4,smooth=False)\n",
        "  rougen=rouge_n(pred_op, real_og, n=2)\n",
        "  ro=rouge(pred_op, real_og)\n",
        "\n",
        "  print(\"bleu, precisions, bp, ratio, translation_length, reference_length\",bleau)\n",
        "  print(\"rouge2\",rougen)\n",
        "  print(\"rouge\",ro)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkWUesN6ofHw"
      },
      "source": [
        "#step24\n",
        "def lstmmodel():\n",
        "  #this the model designed by me for text summarization \n",
        "  st=time.time()\n",
        "  #get the data\n",
        "  xtr,ytr,xtt,ytt,xval,yval,vocab_to_int,int_to_vocab,word_embedding_matrix,max_rl,max_sl=combining_all_steps()\n",
        "  #call the model\n",
        "  encoder_inputs,encoder_outputs, state_h, state_c,decoder_inputs,decoder_lstm,attn_layer,decoder_dense,dec_emb_layer=design_model_fit_eval(xtr,ytr,xval,yval,vocab_to_int,word_embedding_matrix,max_rl)\n",
        "  #get the inference output\n",
        "  encoder_model,decoder_model=design_inference(encoder_inputs,encoder_outputs, state_h, state_c,decoder_inputs,decoder_lstm,attn_layer,decoder_dense,max_rl,dec_emb_layer)\n",
        "  #call test\n",
        "  test_scratch(xtt,ytt,int_to_vocab,vocab_to_int,encoder_model,decoder_model,max_sl,max_rl)\n",
        "  print(\"total time required for completing whole process \",time.time()-st)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4VQixJflQJIa",
        "outputId": "48990924-b6d4-426e-ab89-d0b91d2a1e29"
      },
      "source": [
        "lstmmodel()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of dataset is  180000\n",
            "vocab length 68861\n",
            "Word embeddings: 516783\n",
            "Number of words missing from word_embeddings: 728\n",
            "Percent of words that are missing from our vocabulary: 1.06%\n",
            "Total number of unique words: 68861\n",
            "Number of words we will use: 37429\n",
            "Percent of words we will use: 54.35%\n",
            "length vocab_to_int 37429\n",
            "length int_to_vocab 37429\n",
            "length of word embedding matrix 37429\n",
            "after word to index for reviewText [0, 3910, 0, 17, 12, 119, 278, 209, 79, 905, 3910, 1532]\n",
            "after word to index for summary [37428, 0, 3910, 70, 1154, 565, 37427]\n",
            "total number of unk token are 0\n",
            "length of dataset that will be used 162996\n",
            "length of split datasets train 114097, test 24449 and validation 24450\n",
            "Vocabulary Size: 37429\n",
            "voc_to_int_ 37425 37426 37427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "total time to complete all the above steps and get final data  53.47959923744202\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 80, 300)      11228700    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 80, 80), (No 121920      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 80, 80), (No 51520       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    11228700    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 80, 80), (No 51520       lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 80), ( 121920      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 80), ( 12880       lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 160)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 37429)  6026069     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 28,843,229\n",
            "Trainable params: 6,385,829\n",
            "Non-trainable params: 22,457,400\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "223/223 [==============================] - 1310s 6s/step - loss: 4.0799 - accuracy: 0.5655 - val_loss: 2.4055 - val_accuracy: 0.6474\n",
            "Epoch 2/100\n",
            "223/223 [==============================] - 1291s 6s/step - loss: 2.3758 - accuracy: 0.6486 - val_loss: 2.2830 - val_accuracy: 0.6506\n",
            "Epoch 3/100\n",
            "223/223 [==============================] - 1299s 6s/step - loss: 2.2568 - accuracy: 0.6531 - val_loss: 2.1656 - val_accuracy: 0.6610\n",
            "Epoch 4/100\n",
            "223/223 [==============================] - 1290s 6s/step - loss: 2.1481 - accuracy: 0.6608 - val_loss: 2.0872 - val_accuracy: 0.6671\n",
            "Epoch 5/100\n",
            "223/223 [==============================] - 1294s 6s/step - loss: 2.0641 - accuracy: 0.6677 - val_loss: 2.0271 - val_accuracy: 0.6711\n",
            "Epoch 6/100\n",
            "223/223 [==============================] - 1295s 6s/step - loss: 2.0176 - accuracy: 0.6704 - val_loss: 1.9876 - val_accuracy: 0.6746\n",
            "Epoch 7/100\n",
            "223/223 [==============================] - 1313s 6s/step - loss: 1.9601 - accuracy: 0.6751 - val_loss: 1.9464 - val_accuracy: 0.6782\n",
            "Epoch 8/100\n",
            "223/223 [==============================] - 1328s 6s/step - loss: 1.9243 - accuracy: 0.6784 - val_loss: 1.9192 - val_accuracy: 0.6805\n",
            "Epoch 9/100\n",
            "223/223 [==============================] - 1329s 6s/step - loss: 1.8991 - accuracy: 0.6796 - val_loss: 1.8963 - val_accuracy: 0.6828\n",
            "Epoch 10/100\n",
            "223/223 [==============================] - 1329s 6s/step - loss: 1.8776 - accuracy: 0.6814 - val_loss: 1.8779 - val_accuracy: 0.6849\n",
            "Epoch 11/100\n",
            "223/223 [==============================] - 1325s 6s/step - loss: 1.8457 - accuracy: 0.6848 - val_loss: 1.8619 - val_accuracy: 0.6861\n",
            "Epoch 12/100\n",
            "223/223 [==============================] - 1296s 6s/step - loss: 1.8347 - accuracy: 0.6850 - val_loss: 1.8469 - val_accuracy: 0.6878\n",
            "Epoch 13/100\n",
            "223/223 [==============================] - 1300s 6s/step - loss: 1.8081 - accuracy: 0.6878 - val_loss: 1.8340 - val_accuracy: 0.6893\n",
            "Epoch 14/100\n",
            "223/223 [==============================] - 1302s 6s/step - loss: 1.7984 - accuracy: 0.6882 - val_loss: 1.8251 - val_accuracy: 0.6898\n",
            "Epoch 15/100\n",
            "223/223 [==============================] - 1303s 6s/step - loss: 1.7795 - accuracy: 0.6898 - val_loss: 1.8169 - val_accuracy: 0.6908\n",
            "Epoch 16/100\n",
            "223/223 [==============================] - 1298s 6s/step - loss: 1.7658 - accuracy: 0.6912 - val_loss: 1.8076 - val_accuracy: 0.6918\n",
            "Epoch 17/100\n",
            "223/223 [==============================] - 1314s 6s/step - loss: 1.7582 - accuracy: 0.6917 - val_loss: 1.8003 - val_accuracy: 0.6924\n",
            "Epoch 18/100\n",
            "223/223 [==============================] - 1311s 6s/step - loss: 1.7393 - accuracy: 0.6934 - val_loss: 1.7928 - val_accuracy: 0.6931\n",
            "Epoch 19/100\n",
            "223/223 [==============================] - 1315s 6s/step - loss: 1.7281 - accuracy: 0.6941 - val_loss: 1.7885 - val_accuracy: 0.6938\n",
            "Epoch 20/100\n",
            "223/223 [==============================] - 1324s 6s/step - loss: 1.7233 - accuracy: 0.6943 - val_loss: 1.7839 - val_accuracy: 0.6939\n",
            "Epoch 21/100\n",
            "223/223 [==============================] - 1324s 6s/step - loss: 1.7168 - accuracy: 0.6950 - val_loss: 1.7788 - val_accuracy: 0.6949\n",
            "Epoch 22/100\n",
            "223/223 [==============================] - 1319s 6s/step - loss: 1.7081 - accuracy: 0.6955 - val_loss: 1.7757 - val_accuracy: 0.6953\n",
            "Epoch 23/100\n",
            "223/223 [==============================] - 1305s 6s/step - loss: 1.6971 - accuracy: 0.6968 - val_loss: 1.7720 - val_accuracy: 0.6956\n",
            "Epoch 24/100\n",
            "223/223 [==============================] - 1310s 6s/step - loss: 1.6880 - accuracy: 0.6971 - val_loss: 1.7685 - val_accuracy: 0.6962\n",
            "Epoch 25/100\n",
            "223/223 [==============================] - 1312s 6s/step - loss: 1.6793 - accuracy: 0.6984 - val_loss: 1.7660 - val_accuracy: 0.6962\n",
            "Epoch 26/100\n",
            "223/223 [==============================] - 1313s 6s/step - loss: 1.6760 - accuracy: 0.6981 - val_loss: 1.7632 - val_accuracy: 0.6967\n",
            "Epoch 27/100\n",
            "223/223 [==============================] - 1319s 6s/step - loss: 1.6752 - accuracy: 0.6976 - val_loss: 1.7607 - val_accuracy: 0.6974\n",
            "Epoch 28/100\n",
            "223/223 [==============================] - 1316s 6s/step - loss: 1.6627 - accuracy: 0.6992 - val_loss: 1.7593 - val_accuracy: 0.6971\n",
            "Epoch 29/100\n",
            "223/223 [==============================] - 1317s 6s/step - loss: 1.6541 - accuracy: 0.6999 - val_loss: 1.7572 - val_accuracy: 0.6977\n",
            "Epoch 30/100\n",
            "223/223 [==============================] - 1332s 6s/step - loss: 1.6499 - accuracy: 0.7002 - val_loss: 1.7541 - val_accuracy: 0.6980\n",
            "Epoch 31/100\n",
            "223/223 [==============================] - 1322s 6s/step - loss: 1.6422 - accuracy: 0.7008 - val_loss: 1.7514 - val_accuracy: 0.6983\n",
            "Epoch 32/100\n",
            "223/223 [==============================] - 1325s 6s/step - loss: 1.6308 - accuracy: 0.7014 - val_loss: 1.7511 - val_accuracy: 0.6986\n",
            "Epoch 33/100\n",
            "223/223 [==============================] - 1320s 6s/step - loss: 1.6352 - accuracy: 0.7004 - val_loss: 1.7491 - val_accuracy: 0.6989\n",
            "Epoch 34/100\n",
            "223/223 [==============================] - 1324s 6s/step - loss: 1.6238 - accuracy: 0.7018 - val_loss: 1.7506 - val_accuracy: 0.6986\n",
            "Epoch 35/100\n",
            "223/223 [==============================] - 1319s 6s/step - loss: 1.6210 - accuracy: 0.7024 - val_loss: 1.7488 - val_accuracy: 0.6990\n",
            "Epoch 36/100\n",
            "223/223 [==============================] - 1315s 6s/step - loss: 1.6125 - accuracy: 0.7030 - val_loss: 1.7475 - val_accuracy: 0.6990\n",
            "Epoch 37/100\n",
            "223/223 [==============================] - 1317s 6s/step - loss: 1.6074 - accuracy: 0.7036 - val_loss: 1.7473 - val_accuracy: 0.6993\n",
            "Epoch 38/100\n",
            "223/223 [==============================] - 1318s 6s/step - loss: 1.6092 - accuracy: 0.7030 - val_loss: 1.7469 - val_accuracy: 0.6991\n",
            "Epoch 39/100\n",
            "223/223 [==============================] - 1325s 6s/step - loss: 1.6072 - accuracy: 0.7033 - val_loss: 1.7466 - val_accuracy: 0.6996\n",
            "Epoch 40/100\n",
            "223/223 [==============================] - 1313s 6s/step - loss: 1.5999 - accuracy: 0.7041 - val_loss: 1.7469 - val_accuracy: 0.6992\n",
            "Epoch 41/100\n",
            "223/223 [==============================] - 1309s 6s/step - loss: 1.5963 - accuracy: 0.7041 - val_loss: 1.7455 - val_accuracy: 0.6993\n",
            "Epoch 42/100\n",
            "223/223 [==============================] - 1314s 6s/step - loss: 1.5919 - accuracy: 0.7046 - val_loss: 1.7468 - val_accuracy: 0.6996\n",
            "Epoch 43/100\n",
            "223/223 [==============================] - 1315s 6s/step - loss: 1.5886 - accuracy: 0.7058 - val_loss: 1.7463 - val_accuracy: 0.6995\n",
            "Epoch 44/100\n",
            "223/223 [==============================] - 1316s 6s/step - loss: 1.5804 - accuracy: 0.7060 - val_loss: 1.7470 - val_accuracy: 0.6995\n",
            "Epoch 45/100\n",
            "223/223 [==============================] - 1316s 6s/step - loss: 1.5855 - accuracy: 0.7054 - val_loss: 1.7475 - val_accuracy: 0.6993\n",
            "Epoch 46/100\n",
            "223/223 [==============================] - 1314s 6s/step - loss: 1.5796 - accuracy: 0.7053 - val_loss: 1.7477 - val_accuracy: 0.6993\n",
            "Epoch 00046: early stopping\n",
            "total time required for training  60417.43151330948\n",
            "Review: compared hanes partner company champion hoodie exactly needed cool winter spring fall nights fabric heavy cumbersome pulling head product complaints value compared 34 branded 34 sweats usual service amazon                                                \n",
            "Original Summary: sweat price     \n",
            "Predicted Summary:  great quality       \n",
            "Review: briefs gift feel wear loves looks amazing complaints                                                                         \n",
            "Original Summary: full support in the briefest of briefs  \n",
            "Predicted Summary:  great        \n",
            "Review: took chance shoes match champagne colored dress perfect looking small heel exactly looking quick delivery                                                                  \n",
            "Original Summary: wedding accessories       \n",
            "Predicted Summary:  cute        \n",
            "Review: fit like years ago cheaper quality materials gravity extra weight comfortable socks price                                                                    \n",
            "Original Summary: love them but      \n",
            "Predicted Summary:  good socks       \n",
            "Review: received compliments pair shoes run bit small mind love getting colors                                                                      \n",
            "Original Summary: very cute       \n",
            "Predicted Summary:  great shoes       \n",
            "Review: elegant perfect height beautiful black velvet love necklaces display easy buy necklaces nice good price homework best priced places looked                                                             \n",
            "Original Summary: elegant very nice way to display your necklaces \n",
            "Predicted Summary:  beautiful        \n",
            "Review: styles choose happy got wife said look good block sunlight happy purchase                                                                     \n",
            "Original Summary: cool sunglasses       \n",
            "Predicted Summary:  great        \n",
            "Review: dockers belt quality leather soft touch edging adds extra touch quality attractiveness belt husband happy                                                                  \n",
            "Original Summary: top quality       \n",
            "Predicted Summary:  great belt       \n",
            "Review: boot cold weather sole little stiff need wear minute warm shoe strings look bad tied tie tuck bow tongue shown size runs tad small maybe 1 4 size fleece lining wear 8 5 ordered 9 perfect socks boot ready snow                                        \n",
            "Original Summary: boot for snow fun    \n",
            "Predicted Summary:  great boots       \n",
            "total time to complete 16337.685415506363\n",
            "bleu, precisions, bp, ratio, translation_length, reference_length (0.0, [0.28920270859216957, 0.0, 0.0, 0.0], 1.0, 18.863716307415437, 461199, 24449)\n",
            "rouge2 (0.06396831716529384, 0.8433628318584071, 0.03324495918509733)\n",
            "rouge {'rouge_1/f_score': 0.369937694638666, 'rouge_1/r_score': 0.36391803930046807, 'rouge_1/p_score': 0.4218425689498126, 'rouge_2/f_score': 0.2876825073960605, 'rouge_2/r_score': 0.33199804646796344, 'rouge_2/p_score': 0.2762888831756679, 'rouge_l/f_score': 0.6168180799689316, 'rouge_l/r_score': 0.6627440210817854, 'rouge_l/p_score': 0.586330729273181}\n",
            "total time required for completing whole process  76820.69789242744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euct4cIGtr4u"
      },
      "source": [
        "#summary using T5small pretrained model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quKmq4CvdKGL"
      },
      "source": [
        "#step26\n",
        "#function is used to return the loss\n",
        "def step(inputs_ids, attention_mask, y, pad_token_id, model):\n",
        "  y_ids = y[:, :-1].contiguous()\n",
        "  lm_labels = y[:, 1:].clone()\n",
        "  lm_labels[y[:, 1:] == pad_token_id] = -100\n",
        "  output = model(inputs_ids, attention_mask=attention_mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n",
        "  # loss\n",
        "  return output[0] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15XD1TxRdPN0"
      },
      "source": [
        "#step25\n",
        "#this function is used to train the pretrained t5small model\n",
        "def t5train(train_loader,val_loader,pad_token_id,model,EPOCHS,log_interval):\n",
        "  #initialize empty list for train_loss and val_loss\n",
        "  train_loss = []\n",
        "  val_loss = []\n",
        "  #optimizer\n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=1e-4, weight_decay=1e-4/25)\n",
        "  #iterate for number of epochs\n",
        "  for epoch in range(EPOCHS):\n",
        "    model.train() \n",
        "    #start time\n",
        "    start_time = time.time()\n",
        "    #for data in train_loader train the model\n",
        "    for i, (inputs_ids, attention_mask, y) in enumerate(train_loader):\n",
        "      inputs_ids = inputs_ids.to(device)\n",
        "      attention_mask = attention_mask.to(device)\n",
        "      y = y.to(device)\n",
        "            \n",
        "      optimizer.zero_grad()\n",
        "      loss = step(inputs_ids, attention_mask, y, pad_token_id, model)\n",
        "      train_loss.append(loss.item())\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "      optimizer.step()\n",
        "            \n",
        "      if (i + 1) % log_interval == 0:\n",
        "        with torch.no_grad():\n",
        "          x, x_mask, y = next(iter(val_loader))\n",
        "          x = x.to(device)\n",
        "          x_mask = x_mask.to(device)\n",
        "          y = y.to(device)\n",
        "                \n",
        "          v_loss = step(x, x_mask, y, pad_token_id, model)\n",
        "          v_loss = v_loss.item()\n",
        "                \n",
        "          elapsed = time.time() - start_time\n",
        "          print('| epoch {:3d} | [{:5d}/{:5d}] | '\n",
        "                'ms/batch {:5.2f} | '\n",
        "                'loss {:5.2f} | val loss {:5.2f}'.format(\n",
        "                  epoch, i, len(train_loader),\n",
        "                  elapsed * 1000 / log_interval,\n",
        "                  loss.item(), v_loss))\n",
        "          start_time = time.time()\n",
        "          val_loss.append(v_loss)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYDbQrNxdYdI"
      },
      "source": [
        "#step26\n",
        "#function to test the model it writes original and predicted summary in txt file\n",
        "def testT5(model,tokenizer,test_loader):\n",
        "  #intialize the empty lists\n",
        "  predictions = []\n",
        "  real_og=[]\n",
        "  pred_op=[]\n",
        "  c=0\n",
        "  b=1000\n",
        "  #for data in test loader\n",
        "  for i, (input_ids, attention_mask, y) in enumerate(test_loader):\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    y = y.to(device)\n",
        "    #generate summaries \n",
        "    #store real and predicted summary in a list and write in txt file\n",
        "    summaries = model.generate(input_ids=input_ids, attention_mask=attention_mask,max_length=10)\n",
        "    pred = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summaries]\n",
        "    real = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in y]\n",
        "    for pred_sent, real_sent in zip(pred, real): \n",
        "      if c>b:\n",
        "        print(\"Original: {}\".format(real_sent))\n",
        "        print(\"Predicted: {}\".format(pred_sent))\n",
        "        print(\"\\n\")\n",
        "        b+=b\n",
        "      real_og.append(real_sent)\n",
        "      pred_op.append(pred_sent)\n",
        "      predictions.append(str(\"pred sentence: \" + pred_sent + \"\\t\\t real sentence: \" + real_sent+\"\\n\"))\n",
        "      c+=1\n",
        "  file1 = open(\"/content/drive/MyDrive/TFIVE.txt\",\"w\")\n",
        "  file1.writelines(predictions)\n",
        "  file1.close()\n",
        "  #calculate scores\n",
        "  bleau=compute_bleu(real_og,pred_op, max_order=4,smooth=False)\n",
        "  rougen=rouge_n(pred_op, real_og, n=2)\n",
        "  ro=rouge(pred_op, real_og)\n",
        "\n",
        "  print(\"bleu, precisions, bp, ratio, translation_length, reference_length\",bleau)\n",
        "  print(\"rouge2\",rougen)\n",
        "  print(\"rouge\",ro)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awxFEtTPbMgZ"
      },
      "source": [
        "#step27\n",
        "#fucntion to get the data and call all the functions in a squence\n",
        "def tf5token():\n",
        "  class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, articles, highlights):\n",
        "      self.x = articles\n",
        "      self.y = highlights\n",
        "  \n",
        "    def __getitem__(self,index):\n",
        "      x = tokenizer.encode_plus(model.config.prefix + str(self.x[index]), max_length=80, return_tensors=\"pt\", pad_to_max_length=True)\n",
        "      y = tokenizer.encode(str(self.y[index]), max_length=10, return_tensors=\"pt\", pad_to_max_length=True)\n",
        "      return x['input_ids'].view(-1), x['attention_mask'].view(-1), y.view(-1)\n",
        "        \n",
        "    def __len__(self):\n",
        "      return len(self.x)\n",
        "\n",
        "  #get the data\n",
        "  x_tr,y_tr,x_tt,y_tt,x_val,y_val=combining_all_steps_t5()\n",
        "  BATCH_SIZE = 128\n",
        "  SHUFFEL_SIZE = 1024\n",
        "  EPOCHS = 25\n",
        "  log_interval = 200\n",
        "  #get the pretrained model t5-small\n",
        "  tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "  model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n",
        "\n",
        "  task_specific_params = model.config.task_specific_params\n",
        "  if task_specific_params is not None:\n",
        "    model.config.update(task_specific_params.get(\"summarization\", {}))\n",
        "  \n",
        "  #create train,test and validation datasets\n",
        "  train_ds = MyDataset(x_tr[\"reviewText\"],y_tr[\"summary\"]) \n",
        "  val_ds = MyDataset(x_val[\"reviewText\"],y_val[\"summary\"])\n",
        "  test_ds = MyDataset(x_tt[\"reviewText\"],y_tt[\"summary\"])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
        "  val_loader = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
        "  test_loader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "  x, x_mask, y = next(iter(val_loader))\n",
        "  print(x.shape, x_mask.shape, y.shape)\n",
        "  pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "  #call the train function\n",
        "  model=t5train(train_loader,val_loader,pad_token_id,model,EPOCHS,log_interval)\n",
        "  #call the test function\n",
        "  testT5(model,tokenizer,test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQPZ1GzZx5Ej",
        "outputId": "b4cc7432-d16a-4591-f029-7dfbc7cda163"
      },
      "source": [
        "tf5token()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of dataset is  117799\n",
            "train 82459, val 17670, test 17670\n",
            "torch.Size([128, 80]) torch.Size([128, 80]) torch.Size([128, 10])\n",
            "| epoch   0 | [  199/  645] | ms/batch 376.53 | loss  4.30 | val loss  4.34\n",
            "| epoch   0 | [  399/  645] | ms/batch 375.75 | loss  4.20 | val loss  4.14\n",
            "| epoch   0 | [  599/  645] | ms/batch 376.28 | loss  4.10 | val loss  4.02\n",
            "| epoch   1 | [  199/  645] | ms/batch 376.54 | loss  3.83 | val loss  3.96\n",
            "| epoch   1 | [  399/  645] | ms/batch 375.83 | loss  3.80 | val loss  3.84\n",
            "| epoch   1 | [  599/  645] | ms/batch 376.14 | loss  3.91 | val loss  3.76\n",
            "| epoch   2 | [  199/  645] | ms/batch 376.54 | loss  3.72 | val loss  3.72\n",
            "| epoch   2 | [  399/  645] | ms/batch 375.92 | loss  3.68 | val loss  3.65\n",
            "| epoch   2 | [  599/  645] | ms/batch 376.34 | loss  3.74 | val loss  3.64\n",
            "| epoch   3 | [  199/  645] | ms/batch 376.17 | loss  3.65 | val loss  3.59\n",
            "| epoch   3 | [  399/  645] | ms/batch 376.04 | loss  3.55 | val loss  3.55\n",
            "| epoch   3 | [  599/  645] | ms/batch 376.34 | loss  3.72 | val loss  3.60\n",
            "| epoch   4 | [  199/  645] | ms/batch 375.51 | loss  3.51 | val loss  3.51\n",
            "| epoch   4 | [  399/  645] | ms/batch 375.86 | loss  3.55 | val loss  3.46\n",
            "| epoch   4 | [  599/  645] | ms/batch 375.44 | loss  3.66 | val loss  3.55\n",
            "| epoch   5 | [  199/  645] | ms/batch 375.43 | loss  3.47 | val loss  3.50\n",
            "| epoch   5 | [  399/  645] | ms/batch 375.22 | loss  3.44 | val loss  3.46\n",
            "| epoch   5 | [  599/  645] | ms/batch 375.57 | loss  3.56 | val loss  3.41\n",
            "| epoch   6 | [  199/  645] | ms/batch 375.31 | loss  3.37 | val loss  3.42\n",
            "| epoch   6 | [  399/  645] | ms/batch 375.19 | loss  3.40 | val loss  3.39\n",
            "| epoch   6 | [  599/  645] | ms/batch 375.01 | loss  3.50 | val loss  3.37\n",
            "| epoch   7 | [  199/  645] | ms/batch 376.42 | loss  3.27 | val loss  3.33\n",
            "| epoch   7 | [  399/  645] | ms/batch 375.57 | loss  3.29 | val loss  3.41\n",
            "| epoch   7 | [  599/  645] | ms/batch 375.58 | loss  3.40 | val loss  3.36\n",
            "| epoch   8 | [  199/  645] | ms/batch 375.81 | loss  3.25 | val loss  3.38\n",
            "| epoch   8 | [  399/  645] | ms/batch 375.75 | loss  3.31 | val loss  3.32\n",
            "| epoch   8 | [  599/  645] | ms/batch 375.23 | loss  3.37 | val loss  3.28\n",
            "| epoch   9 | [  199/  645] | ms/batch 375.49 | loss  3.21 | val loss  3.38\n",
            "| epoch   9 | [  399/  645] | ms/batch 375.22 | loss  3.22 | val loss  3.35\n",
            "| epoch   9 | [  599/  645] | ms/batch 374.88 | loss  3.35 | val loss  3.28\n",
            "| epoch  10 | [  199/  645] | ms/batch 375.19 | loss  3.16 | val loss  3.34\n",
            "| epoch  10 | [  399/  645] | ms/batch 375.17 | loss  3.20 | val loss  3.35\n",
            "| epoch  10 | [  599/  645] | ms/batch 375.38 | loss  3.34 | val loss  3.35\n",
            "| epoch  11 | [  199/  645] | ms/batch 375.66 | loss  3.12 | val loss  3.27\n",
            "| epoch  11 | [  399/  645] | ms/batch 375.53 | loss  3.20 | val loss  3.24\n",
            "| epoch  11 | [  599/  645] | ms/batch 375.73 | loss  3.33 | val loss  3.32\n",
            "| epoch  12 | [  199/  645] | ms/batch 375.64 | loss  3.09 | val loss  3.29\n",
            "| epoch  12 | [  399/  645] | ms/batch 375.43 | loss  3.08 | val loss  3.29\n",
            "| epoch  12 | [  599/  645] | ms/batch 375.37 | loss  3.30 | val loss  3.30\n",
            "| epoch  13 | [  199/  645] | ms/batch 375.48 | loss  3.10 | val loss  3.24\n",
            "| epoch  13 | [  399/  645] | ms/batch 375.24 | loss  3.03 | val loss  3.27\n",
            "| epoch  13 | [  599/  645] | ms/batch 375.39 | loss  3.20 | val loss  3.22\n",
            "| epoch  14 | [  199/  645] | ms/batch 375.37 | loss  3.06 | val loss  3.29\n",
            "| epoch  14 | [  399/  645] | ms/batch 375.74 | loss  3.07 | val loss  3.25\n",
            "| epoch  14 | [  599/  645] | ms/batch 375.73 | loss  3.17 | val loss  3.26\n",
            "| epoch  15 | [  199/  645] | ms/batch 375.19 | loss  2.98 | val loss  3.24\n",
            "| epoch  15 | [  399/  645] | ms/batch 375.56 | loss  3.00 | val loss  3.29\n",
            "| epoch  15 | [  599/  645] | ms/batch 376.06 | loss  3.14 | val loss  3.26\n",
            "| epoch  16 | [  199/  645] | ms/batch 375.74 | loss  3.01 | val loss  3.24\n",
            "| epoch  16 | [  399/  645] | ms/batch 375.22 | loss  2.99 | val loss  3.33\n",
            "| epoch  16 | [  599/  645] | ms/batch 375.30 | loss  3.12 | val loss  3.28\n",
            "| epoch  17 | [  199/  645] | ms/batch 376.03 | loss  2.95 | val loss  3.20\n",
            "| epoch  17 | [  399/  645] | ms/batch 375.74 | loss  2.92 | val loss  3.22\n",
            "| epoch  17 | [  599/  645] | ms/batch 374.76 | loss  3.06 | val loss  3.18\n",
            "| epoch  18 | [  199/  645] | ms/batch 375.26 | loss  2.84 | val loss  3.27\n",
            "| epoch  18 | [  399/  645] | ms/batch 375.06 | loss  2.90 | val loss  3.24\n",
            "| epoch  18 | [  599/  645] | ms/batch 375.57 | loss  3.04 | val loss  3.23\n",
            "| epoch  19 | [  199/  645] | ms/batch 375.42 | loss  2.88 | val loss  3.30\n",
            "| epoch  19 | [  399/  645] | ms/batch 375.98 | loss  2.94 | val loss  3.31\n",
            "| epoch  19 | [  599/  645] | ms/batch 375.37 | loss  3.01 | val loss  3.23\n",
            "| epoch  20 | [  199/  645] | ms/batch 375.75 | loss  2.86 | val loss  3.25\n",
            "| epoch  20 | [  399/  645] | ms/batch 375.00 | loss  2.87 | val loss  3.15\n",
            "| epoch  20 | [  599/  645] | ms/batch 375.34 | loss  3.01 | val loss  3.23\n",
            "| epoch  21 | [  199/  645] | ms/batch 375.16 | loss  2.85 | val loss  3.31\n",
            "| epoch  21 | [  399/  645] | ms/batch 375.18 | loss  2.82 | val loss  3.26\n",
            "| epoch  21 | [  599/  645] | ms/batch 375.80 | loss  2.89 | val loss  3.25\n",
            "| epoch  22 | [  199/  645] | ms/batch 375.28 | loss  2.78 | val loss  3.29\n",
            "| epoch  22 | [  399/  645] | ms/batch 375.48 | loss  2.81 | val loss  3.18\n",
            "| epoch  22 | [  599/  645] | ms/batch 375.56 | loss  2.91 | val loss  3.25\n",
            "| epoch  23 | [  199/  645] | ms/batch 375.62 | loss  2.86 | val loss  3.22\n",
            "| epoch  23 | [  399/  645] | ms/batch 375.49 | loss  2.78 | val loss  3.16\n",
            "| epoch  23 | [  599/  645] | ms/batch 375.53 | loss  2.98 | val loss  3.29\n",
            "| epoch  24 | [  199/  645] | ms/batch 375.32 | loss  2.80 | val loss  3.30\n",
            "| epoch  24 | [  399/  645] | ms/batch 375.17 | loss  2.77 | val loss  3.26\n",
            "| epoch  24 | [  599/  645] | ms/batch 375.57 | loss  2.85 | val loss  3.26\n",
            "Original: poor band design\n",
            "Predicted: watch huge faces 2 1 2 including a\n",
            "\n",
            "\n",
            "Original: it was nice but\n",
            "Predicted: the face is way too big for me but\n",
            "\n",
            "\n",
            "Original: perfect for touring musician\n",
            "Predicted: a gift for my daughter who loves it\n",
            "\n",
            "\n",
            "Original: runs extremely small\n",
            "Predicted: sizes are a bit larger than i\n",
            "\n",
            "\n",
            "Original: gets the job done for a great bargain\n",
            "Predicted: wait for a few days and wait for\n",
            "\n",
            "\n",
            "bleu, precisions, bp, ratio, translation_length, reference_length (0.0, [0.2630167992797705, 0.0, 0.0, 0.0], 1.0, 31.05342388228636, 548714, 17670)\n",
            "rouge2 (0.19756874278857312, 0.20103278491653656, 0.19422206752523494)\n",
            "rouge {'rouge_1/f_score': 0.09624047102839747, 'rouge_1/r_score': 0.14699771381859666, 'rouge_1/p_score': 0.0800835197312277, 'rouge_2/f_score': 0.01807366492575748, 'rouge_2/r_score': 0.0314447184268916, 'rouge_2/p_score': 0.014622914813916511, 'rouge_l/f_score': 0.07362638196379556, 'rouge_l/r_score': 0.1396654494659588, 'rouge_l/p_score': 0.07113496105856036}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Yc0HUt-zQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f9ff01a-a1c4-481e-ea4f-0f97aacf24e5"
      },
      "source": [
        "#get the final cleaned data\n",
        "df=pd.read_csv('/content/drive/MyDrive/product_reviews.csv')[:117799]\n",
        "print(\"The length of dataset is \",len(df))\n",
        "  \n",
        "#set the threshold \n",
        "threshold = 20\n",
        "max_rl=80 #maximum review length\n",
        "max_sl=10 #maximum summary length\n",
        "  \n",
        "#get reviewText whose length is less than maximum review length\n",
        "df['reviewText']=df['reviewText'].str.slice(0,max_rl)\n",
        "  \n",
        "#get summary whose length is less than maximum summary length\n",
        "df['summary']=df['summary'].str.slice(0,max_rl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of dataset is  117799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdyLxZeSd0Pc"
      },
      "source": [
        "'''\n",
        "f = open(\"/content/drive/MyDrive/TFIVE.txt\", \"r\")\n",
        "text=f.readlines()\n",
        "text=pd.DataFrame(text,columns=[\"value\"])\n",
        "text=text[\"value\"].str.split(\"\\t\",expand=True)\n",
        "text.columns=[\"predicted\",\"value\",\"original\"]\n",
        "text.drop(columns=[\"value\"],inplace=True)\n",
        "text[\"predicted\"]=text[\"predicted\"].str.split(\":\").str[1]\n",
        "text[\"original\"]=text[\"original\"].str.split(\":\").str[1]\n",
        "text[\"original\"]=text[\"original\"].replace('\\n','', regex=True)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "9xxGTrOobUY0",
        "outputId": "2c65564a-c668-41a8-932c-84f5fc206ddf"
      },
      "source": [
        "df[df[\"summary\"]=='best birthday gift ever']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21619</th>\n",
              "      <td>got today birthday wow cozy super shocked gift...</td>\n",
              "      <td>best birthday gift ever</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              reviewText                  summary\n",
              "21619  got today birthday wow cozy super shocked gift...  best birthday gift ever"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Awltwub5pjsq",
        "outputId": "51a0a623-f370-4669-a6f4-37d8b3c3bee4"
      },
      "source": [
        "df[\"reviewText\"][21619]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'got today birthday wow cozy super shocked gift wanted uggs money reading plan pu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "jQyLzrwxptGE",
        "outputId": "38255f78-f5ff-437d-849e-4e52f297b98f"
      },
      "source": [
        "df[\"reviewText\"][86599]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bought 5 red cute totally loves wants wear single day sensitive shoes clothes aw'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "V-sqiznJqYQD",
        "outputId": "8d25f6a0-7723-4cf3-c7c6-cabb4d526111"
      },
      "source": [
        "df[\"original\"][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' i like it but changed a lot once'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DniBOgWfqepc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}